# ADR-004: httpx como HTTP Client

**Status**: Aceito
**Data**: 2025-12-03
**Decisores**: Stakeholder

## Contexto

O ForgeLLMClient precisa fazer requisicoes HTTP para APIs de provedores LLM.
Requisitos:
- Suporte a async (para streaming)
- Timeout configuravel
- Retry configuravel
- Headers customizaveis
- Suporte a SSE (Server-Sent Events) para streaming

## Decisao

Usar **httpx** como HTTP client para todas as requisicoes aos provedores.

### Justificativa

- **Async nativo**: Suporta `async/await` nativamente
- **API moderna**: Similar a `requests` mas com async
- **Streaming**: Suporte excelente a streaming responses
- **HTTP/2**: Suporte nativo
- **Timeout**: Configuracao granular de timeouts
- **Retry**: Facil implementar retry com backoff

### Exemplo de Uso

```python
import httpx

async def chat_stream(self, messages: list[Message]):
    async with httpx.AsyncClient() as client:
        async with client.stream(
            "POST",
            "https://api.openai.com/v1/responses",
            json={"model": "gpt-4", "input": messages, "stream": True},
            headers={"Authorization": f"Bearer {self.api_key}"},
            timeout=httpx.Timeout(60.0, connect=10.0)
        ) as response:
            async for line in response.aiter_lines():
                yield parse_sse_line(line)
```

## Alternativas Consideradas

### 1. requests (sync)
- **Pros**: Familiar, simples, muito documentado
- **Contras**: NAO suporta async nativo, streaming complicado

### 2. aiohttp
- **Pros**: Maduro, performatico
- **Contras**: API menos intuitiva, mais verboso

### 3. httpx (ESCOLHIDA)
- **Pros**: Async nativo, API similar a requests, streaming excelente
- **Contras**: Dependencia adicional

## Consequencias

### Positivas
- Codigo async limpo e legivel
- Streaming funciona naturalmente
- Facil configurar timeouts e retries
- Compativel com pytest-asyncio

### Negativas
- Dependencia adicional no projeto
- Desenvolvedores precisam conhecer async/await

## Configuracao Recomendada

```python
# Configuracao padrao do cliente
client = httpx.AsyncClient(
    timeout=httpx.Timeout(
        connect=10.0,    # timeout de conexao
        read=60.0,       # timeout de leitura
        write=10.0,      # timeout de escrita
        pool=5.0         # timeout de pool
    ),
    limits=httpx.Limits(
        max_keepalive_connections=5,
        max_connections=10
    )
)
```

## Validacao

- [ ] Todas as requisicoes HTTP usam httpx
- [ ] Streaming funciona corretamente
- [ ] Timeouts estao configurados
- [ ] Testes async passam

## Referencias

- https://www.python-httpx.org/
- https://www.python-httpx.org/async/
